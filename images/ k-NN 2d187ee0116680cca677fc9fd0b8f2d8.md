# [대학원 인턴 대비] k-NN

# k-NN 알고리즘 [구현 과정] 중 의문 & 조사 결과

## Q1. Voting 과정에서 loop를 벡터화하지 않는 이유?

- np.bincount()가 1차원 전용 함수이기 때문
    
    한꺼번에 bincount()를 연산하려면 트릭을 사용해야 하는데, 해당 트릭은 내부적으로 loop를 돌기 때문에 속도 이득이 거의 없음
    
- 메모리 사용량에서 벡터화하는 것이 불리함
    
    만약 루프 없이 완벽하게 벡터화를 하려면, 해당 (거대한) 행렬을 메모리에 올리는 것만으로도 컴퓨터가 멈출 수 있음
    • 반면, `for` 루프를 쓰면 **한 번에 한 행만** 처리하므로 메모리를 아주 적게 사용
    
- performance vs complexity
    
    거리 계산의 경우: (벡터화 시) 성능 향상으로 얻는 이득 > 저하되는 가독성으로 인한 손해
    
    voting의 경우: (벡터화 시) 성능 향상으로 얻는 이득 < 저하되는 가독성으로 인한 손해
    

## Q2. 구현 결과의  정확도(27.80%)가 의미하는 것?

- **Good: 무작위 추측보다 높은 정확도**
CIFAR-10은 10개의 클래스를 가지고 있으므로, random하게 추측했을 때 정확도는 약 10%일 것임.
방금 만든 k-NN의 경우 무작위 추측의 약 2.8배의 정확도를 가지고 있음.
    
    
- **Bad: 정확도가 '아주 높지는 않음'.** 
이유를 조사해보니 k-NN은 단순히 픽셀 값의 거리만을 비교하기 때문에 배경 색의 변화, 물체의 약간의 회전만 가해져도 다른 이미지라고 판단함.
따라서 태생적으로 고성능(예: 90% 이상-CNN)을 내기 어려움
    
    

---

# **CIFAR-10 k-NN 분류기 성능 개선 프로젝트**

## 요약

- **배경 및 목적:** CIFAR-10 데이터셋을 활용하여 기초적인 k-NN 알고리즘을 기초부터 구현하고 성능을 측정함.
- **실험 및 분석:**
    ◦ K값에 따른 정확도 변화를 그래프로 시각화함.
    ◦ K=12에서의 급락 원인을 '짝수 시 동점 문제'와 '샘플 노이즈' 관점에서 분석함.
- **결론:** 본 데이터셋에서는 K=10이 최적임을 확인. 이미지 픽셀 거리 기반 방식의 한계를 파악함.

## 결과

![(by matplotlib, datasets: CIFAR-10, used 500 examples)](%5B%EB%8C%80%ED%95%99%EC%9B%90%20%EC%9D%B8%ED%84%B4%20%EB%8C%80%EB%B9%84%5D%20k-NN/%E1%84%89%E1%85%B3%E1%84%8F%E1%85%B3%E1%84%85%E1%85%B5%E1%86%AB%E1%84%89%E1%85%A3%E1%86%BA_2025-12-22_%E1%84%8B%E1%85%A9%E1%84%92%E1%85%AE_6.13.27.png)

(by matplotlib, datasets: CIFAR-10, used 500 examples)

# 의문점 & 조사 결과

## Q1. k값이 커질수록 전반적으로 하강하는 이유?

k값이 커질수록 투표에 참여하는 지나치게 먼 이웃(비슷하지 않은 이미지)의 수가 늘어 ‘가까운 데이터’ 대신 ‘다수인 데이터’가 미치는 영향이 커지기 때문이다. 과소적합(underfitting) 상태가 됨.

## **Q2. k=12에서 국소적인 급락이 일어난 이유?**

1. 짝수로 인한 동점: k가 짝수면 동점일 확률이 발생하는데, 이때 프로그램 내부적으로 랜덤하거나 인덱스가 빠른 것을 선택하게 됨. 이때 정확도가 떨어질 수 있음.(따라서 보통 k-NN에서는 홀수를 선호함)
2. 적은 샘플 수로 인한 노이즈: test data(500장)이 전체 CIFAR-10에 비해 매우 적은 양이므로 k=12의 범위에서 운이 나쁘게 노이즈가 포함된 샘플들이 많았을 가능성이 있다.  

---

# Sample 크기 변화에 따른 최적 k값의 변화(**CIFAR-10)**

## 1. Sample 크기가 증가(5,000 → 50,000)

- 가설: 최적 k값은 증가할 것이다.
    - 예상 이유: 훈련 데이터의 밀도가 높아짐 →
        1. 같은 k값일 경우 더 좁은 영역에서 샘플 확보 가능 → 같은 영역이려면 k값이 더 커져야 함.
        2. 이미 정답을 많이 가지고 있음 → 노이즈의 영향을 덜 받게 됨 → 더 큰 k값을 사용 가능
- 실험 설계: 지난 시간에 작성한 CIFAR-10 k-NN 분류기의 코드를 일부 수정, num_training을 5,000에서 50,000으로 10배 증가시킴. 해당 부분을 제외한 코드는 동일하게 유지하고 최적의 k값 추출
- 실험 결과:

![**오히려 k=10에서 k=8로 최적의 k값이 감소했다!**](%5B%EB%8C%80%ED%95%99%EC%9B%90%20%EC%9D%B8%ED%84%B4%20%EB%8C%80%EB%B9%84%5D%20k-NN/%E1%84%89%E1%85%B3%E1%84%8F%E1%85%B3%E1%84%85%E1%85%B5%E1%86%AB%E1%84%89%E1%85%A3%E1%86%BA_2025-12-25_%E1%84%8B%E1%85%A9%E1%84%92%E1%85%AE_5.11.28.png)

**오히려 k=10에서 k=8로 최적의 k값이 감소했다!**

### sample 크기가 커졌는데도 최적 k값이 오히려 감소한 이유?

이러한 의외의 결과가 나온 이유를 찾아보았다. 

1. 차원의 저주: CIFAR-10은 3,072차원의 아주 거대한 공간이므로 50,000개도 여전히 매우 성긴 샘플일 수도 있다. 
2. L2 거리 측정이 가진 태생적인 한계: 감소한 이유라기보다는 샘플 크기를 늘려도 정확도가 30% 가량에서 정체한 이유다.  L2 거리는 ‘모든’ 픽셀이 ‘독립적으로’ 다른 정도의 합을 측정한다. 이때 선(엣지)의 차이는 작은 부분의 차이이므로 영향이 비교적 적고, 색깔의 차이는 (특히 배경색 등에서) 면적이 거대하므로, 영향이 비교적 크다. 따라서 실제 동일한 사물인지를 결정하는 데 결정적인 ‘선’, 즉 형태가 상대적으로 덜 중요한 ‘색’의 영향을 지나치게 많이 받게 되어 결과가 부정확하다. → 따라서 현재 k-nn은 실무에서 거의 사용되지 않음

## 2. sample의 크기를 차원의 저주를 극복할 만큼 아주 많이 키우면 k-nn 분류기의 성능이 향상될까?

이론적으로는 가능하지만 현실적으로 불가능하다.

1. 크기 10의 작은 공간이라고 할 때, 1 간격으로 점을 찍고 싶다면 3072차원의 경우 10^3072개의 데이터가 필요함
2. 현실에서 이러한 조건을 만족시키는 것은 매우 어려움
3. **거리의 수렴 현상**: 데이터가 3,072차원처럼 매우 큰 차원에 있으면 서로 다른 두 점간의 거리가 모두 비슷비슷하게 매우 커진다 → 변별력을 상실함. 
4. 직관적 이해를 위한 시각 자료

![숫자는 무시하고 형태만 보자.](%5B%EB%8C%80%ED%95%99%EC%9B%90%20%EC%9D%B8%ED%84%B4%20%EB%8C%80%EB%B9%84%5D%20k-NN/image.png)

숫자는 무시하고 형태만 보자.

일반적으로 데이터가 늘어날 때 성능은 로그함수 형태의 곡선을 그린다. 5,000 → 50,000로의 증가는 꽤 초반부터의 구간(10% → 100%)이므로 폭발적인 성능 향상이 가능한 구간이다. 그러나 여기서 5%라는 작은 성능 향상을 보인 것은 낮은 성능이 데이터의 양만의 문제가 아니라는 것을 의미한다.